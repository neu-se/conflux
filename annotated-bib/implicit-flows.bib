@techreport{samarati-protect,
    author = {{P.} Samarati and {L.} Sweeney},
    title = {Protecting Privacy when Disclosing Information: k-Anonymity and its Enforcement through Generalization and Suppression},
    year= {1998},
    url = {http://www.csl.sri.com/papers/sritr-98-04/},
    booktitle = {Technical Report {SRI-CSL-98-04}},
    publisher = {Computer Science Laboratory, {SRI} International},
    annote = {
    Samarati and Sweeney put forward a metric for quantifying the degree to which data is annoymized, k-anonymity.
    	They establish that certain combinations of attributes can be used to uniquely identify an individual or a small set of individuals.
    	A release of data is said to observe k-anonymity if every combination of ``quasi-identifiers'', controlled attributes, can be matched to at least k individuals.
    	The authors were not discussing privacy in the context of information flow analysis.
    	However, k-anonymity could be used evaluate the likelihood that input data can be inferred from output data.
    	Thus, it could be used provide a basis for a more flexible privacy-oriented information flow policy than noninterference.
    }
}

@article{Sabelfeld:2006:LIS:2312191.2314769,
    author = {Sabelfeld, A. and Myers, A. C.},
    title = {Language-based Information-flow Security},
    journal = {IEEE J.Sel. A. Commun.},
    issue_date = {September 2006},
    volume = {21},
    number = {1},
    month = sep,
    year = {2006},
    issn = {0733-8716},
    pages = {5--19},
    numpages = {15},
    url = {https://doi.org/10.1109/JSAC.2002.806121},
    doi = {10.1109/JSAC.2002.806121},
    acmid = {2314769},
    publisher = {IEEE Press},
    address = {Piscataway, NJ, USA},
    annote = {
    Sabelfeld and Myers explore approaches to security-type systems and semantics-based security models for enforcing information-flow confidentiality policies.
	    They contend that since confidentiality is property of all the execution paths of a program, it is more viable to prove that confidentiality policies are enforced with static type-checking approaches than dynamic enforcement.
	    The authors describe implicit flows as a form of ``convert'' channel through which confidential information may be leaked as a result of the control structure of the program.
	    The paper focuses on a noninterference policy for confidentiality in which confidential data is prohibited from causing an observable difference in output.
	    However, they also briefly discuss more relaxed policies, such as selective declassification which allows the confidentiality of data to be ``downgraded'' by certain entities, and quantitative security which allows a limited amount of information to leak.
	}
}

@inproceedings{Clause:2007:DGD:1273463.1273490,
    author = {Clause, James and Li, Wanchun and Orso, Alessandro},
    title = {Dytan: A Generic Dynamic Taint Analysis Framework},
    booktitle = {Proceedings of the 2007 International Symposium on Software Testing and Analysis},
    series = {ISSTA '07},
    year = {2007},
    isbn = {978-1-59593-734-6},
    location = {London, United Kingdom},
    pages = {196--206},
    numpages = {11},
    url = {http://doi.acm.org/10.1145/1273463.1273490},
    doi = {10.1145/1273463.1273490},
    acmid = {1273490},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {dynamic tainting, general framework, information flow},
    annote = {
    Clause \etal discuss a flexible dynamic tainting framework that could be used for various security and software engineering purposes, such as attack detection, enforcing flow policies for sensitive information, software testing, and debugging.
        The authors advocate for a flexible dynamic tainting framework that allows user to select taint propagation policies, specify different taint markings, define custom logic for checking taint markings and combine source operand taints on destination values, and choose different taint source and sink locations.
        They also argue that the dynamic tainting framework should be able to track not only explicit flows due to data dependences, but also offer the option to track implicit flows where tainted value impacts another variable's value indirectly, in particular those due to control dependences.
        Control dependences are informally defined: ``a statement s\textsubscript{2} is control dependent on a statement s\textsubscript{1} if (1) s\textsubscript{1} contains a predicate, and (2) depending on the outcome of s\textsubscript{1} , s\textsubscript{2} may not to be executed.''
        A more formal definition in terms of control flow graphs and post-dominators is also provided.
        In order to partially address conditional instructions whose branches impact different memory locations, the authors suggest adding identity definitions to ensure that the sets of memory locations impacted by two branches match.
        Clause \etal implemented and evaluated, Dytan, a flexible dynamic tainting framework implementation for x86 executables.
        Two techniques from prior studies were replicated using Dytan, an approach for the prevention of overwrite attacks and a positive tainting approach for detecting SQL injection.
        Dytan produced similar results to the original task-specific implementations for both techniques, but Dytan's flexibility impacted its time and space efficiency compared to task-specific implementations.
        The authors also used Dytan to evaluate the number of tainted bytes for different taint-propagation approaches.
        However, the correctness of Dytan's control flow propagation policies was not evaluated.
    }
}

@inproceedings{McCamant:2008:QIF:1375581.1375606,
    author = {McCamant, Stephen and Ernst, Michael D.},
    title = {Quantitative Information Flow As Network Flow Capacity},
    booktitle = {Proceedings of the 29th ACM SIGPLAN Conference on Programming Language Design and Implementation},
    series = {PLDI '08},
    year = {2008},
    isbn = {978-1-59593-860-2},
    location = {Tucson, AZ, USA},
    pages = {193--205},
    numpages = {13},
    url = {http://doi.acm.org/10.1145/1375581.1375606},
    doi = {10.1145/1375581.1375606},
    acmid = {1375606},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {dynamic analysis, implicit flow, information-flow analysis},
    annote = {
    McCamant and Ernst measure the maximum flow of secret information with a network flow capacity model instead of taint tracking.
	    They reason that is may be acceptable for a portion of private information to leak, \eg the last four digits of a credit card number.
	    Thus, it is more practical to use a quantitative approach information-flow security which detects if number of leaked bits exceeds the acceptable limit placed by a confidentiality policy.
	    Their approach observes the execution of a program in order to measure the extent to which private inputs were leaked to public outputs for the execution.
	    Both explicit flows and implicit flows, which they define as those ``in which the value of a variable depends on a previous secret branch condition or pointer value'', are modeled.
	    A graph of potential secret flows is constructed with edges representing values, edge weights conveying the number of bits that a value can hold, and nodes representing operations on values.
	    The source node is used to represent secret inputs and a sink node is used to represent public outputs.
	    Implicit flows are modeled by adding edges to connect each implicit flow operation to the outputs of enclosed computational regions.
	    By default entire program is considered as a enclosed computation.
	    However, addition enclosed regions for sub-computations can be defined to increase the model's precision.
	    The authors' implementation of their approach, Flowcheck, works on x86 executables and uses the Valgrind Framework.
	    Flowcheck was run on bzip2, a lossless compression tool, and reported a flow that was within pre-calculated expected bounds.
	    Additionally, case studies of confidentiality properties in real programs were conducted using Flowcheck and found a previously unknown bug that violated confidentiality.
	    McCamant and Ernst offer a unique technique for addressing implicit flows and a practical approach for enforcing confidentiality policies.
    }
}

@inproceedings{Bao:2010:SCD:1831708.1831711,
    author = {Bao, Tao and Zheng, Yunhui and Lin, Zhiqiang and Zhang, Xiangyu and Xu, Dongyan},
    title = {Strict Control Dependence and Its Effect on Dynamic Information Flow Analyses},
    booktitle = {Proceedings of the 19th International Symposium on Software Testing and Analysis},
    series = {ISSTA '10},
    year = {2010},
    isbn = {978-1-60558-823-0},
    location = {Trento, Italy},
    pages = {13--24},
    numpages = {12},
    url = {http://doi.acm.org/10.1145/1831708.1831711},
    doi = {10.1145/1831708.1831711},
    acmid = {1831711},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {control dependence, data dependence, dynamic information flow, strict control dependence, taint analysis},
    annote = {
		The authors introduce the term strict control dependence (SCD) to refer to implicit flows where there is a strong, almost data flow like, correlation between statements.
		They identify such SCDs as a source of improperly tracked information leaks that may cause false negative in an analysis.
		SCDs are controls flows where ``the equivalence of the left-hand side and the right-hand side expressions of the predicate can be inferred''.
		The effectiveness of considering SCDs was evaluated using three analyzer implementations for GCC-4.4.0: one that only considered data flows, one that considered data flows and all control flows, and one that considered data flow and only strict control flows.
		The analyzers were run on 8 different programs and the authors found that the implementation that considered strict control flows had a lower overhead and fewer false positives than the one that considered all control flows and fewer false negative than the one that considered only data flows.
	}
    % Also discuss execution omission error/negative implicit flow issue - like Dytan they use dummy identity assignments to remedy differences between the branches
}

@inproceedings{Kang2011DTADT,
    title = {DTA++: Dynamic Taint Analysis with Targeted Control-Flow Propagation},
    author = {Min Gyung Kang and Stephen McCamant and Pongsin Poosankam and Dawn Xiaodong Song},
    booktitle = {NDSS},
    year = {2011},
    annote = {
    Similar to Bao \etal \cite{Bao:2010:SCD:1831708.1831711}, Kang \etal propose propagating taints only along select control flows in order to address under-tainting.
    	Inparticular, they target controls flows associated with ``information-preserving'' transformations, which are defined as being transformations that have the properties of an injective function.
        To identify branches related to ``information-preserving'' transformations, they first perform dynamic analysis to collect execution traces.
        Then, they analyze the execution traces to find control-flow paths that can only be reached by a single input value.
        Propagation rules are generated to mitigate under-tainting along the branches of these control-flow paths.
        Lastly, the dynamic analysis is rerun with the generated rules.
        The authors evaluated an implementation of their approach by tracking the flow of sensitive information in word processing applications and found that it successfully addressed under-tainting in that context.
		Kang \etal demonstrate an approach for mitigating a specific form of under-tainting caused by not propagating taints along control flows.
        However, they do not generally examine under-tainting from control flows.
        Some mention is made of instances where a branch causes some value to not be written, which the authors refer to as ``negative'' implicit flows, and technique similar to Clause \etal's \cite{Clause:2007:DGD:1273463.1273490} for partially mitigating simple instances of such flows is discussed.
    }
}

@phdthesis{Jee2015DFT,
    title    = {On Efficiency and Accuracy of Data Flow Tracking Systems},
    school   = {Columbia University},
    author   = {Jee, Kangkook},
    year     = {2015},
    doi = {10.7916/D8MG7P9D},
    url = {https://doi.org/10.7916/D8MG7P9D},
    pages = content,
    annote = {
    Jee presents TaintMark, a dynamic data flow tracking evalution tool for the Android Framework.
    	TaintMark looks at system outputs when given different input values to determine if taints should propagate from the inputs to the outputs.
    	It tests applications with different tainted input values from sources like GPS device, IMSI, IMEI, and password data.
    	During the execution, file and network activities performed by the application are logged for analysis.
    	Logged outputs are compared; differences in the outputs for different input values are interpreted as meaning that taint from the input should have propagated to the output.
    	Non-deterministic output is addressed by re-testing an application with the same input.
    	Outputs that vary for the same input are removed and outputs' field that vary for the same input are excluded when comparing outputs.
    	TaintMark also provides support for debugging reported inaccuracies.
    }
}

@inproceedings{Pauck:2018:ATA:3236024.3236029,
    author = {Pauck, Felix and Bodden, Eric and Wehrheim, Heike},
    title = {Do Android Taint Analysis Tools Keep Their Promises?},
    booktitle = {Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
    series = {ESEC/FSE 2018},
    year = {2018},
    isbn = {978-1-4503-5573-5},
    location = {Lake Buena Vista, FL, USA},
    pages = {331--341},
    numpages = {11},
    url = {http://doi.acm.org/10.1145/3236024.3236029},
    doi = {10.1145/3236024.3236029},
    acmid = {3236029},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {Android Taint Analysis, Benchmarks, Empirical Studies, Reproducibility, Tools},
    annote = {
    Pauck \etal introduce ReproDroid a framework for comparing Android taint analysis tools using a precise, consistent evaluation target.
        The authors establish that popular micro-benchmarks like DroidBench and ICC-Bench specify only the number of leaks that a should be detected for a particular test not the exact leaks that should be detected.
        As a result, these micro-benchmarks can often have imprecise results.
        Furthermore evaluations that use real-world apps are hard to reproduce, may not evaluate whether reported leaks represent true flows, and often cannot determine if true leaks were missed.
        ReproDroid offers a way of converting a tools' results to a standard format, provides a language to describe flows found by a tool, and facilitates the refinement of existing benchmarks through the use of a wizard.
        This wizard allows users to deselect or combine (in order to unify different definitions used by different tools) considered sources and sinks thereby adding necessary information for identifying exact leaks.
        Additionally, the wizard assists with manual classification of true positive and negative test cases.
        The authors note that this manual determination of the ground truth is necessary because, ``tools that could potentially be used to derive the ground truth are at the same time the tools we want to evaluate.''
        They extended the TaintDroid framework to add benchmark cases specifically aimed at evaluating features promised by popular Android taint analysis tools and created some benchmark cases from the 30 Real-world apps in DIALDroid-Bench by manually investigating their source code.
        ReproDroid was used to evaluate whether 6 popular Android taint analysis tools truly supported features that they purported to support, and were truly as accurate as was claimed.
        ReproDroid determined that generally features promised by the tools were fully supported, but that the tools' F-measures were typically lower than promised values.
        Pauck \etal's human-guided approach to benchmark development and refinement contrasts with Jee's automated approach \cite{Jee2015DFT}.
        Furthermore, they provide a strong argument against automated approaches for determining the ground truth of taint analyses.
    }
}

@techreport{Luo:QualitativeAnalysis,
    author = {Luo, Linghui and Bodden, Eric and Sp{\"a}th, Johannes},
    title = {A Qualitative Analysis of Taint-Analysis Results},
    institution = {Heinz Nixdorf Institute, Paderborn University},
    month = aug,
    year = {2018},
    annote = {
    Luo \etal analyze the conditions under which taint-flows reported by the static taint analysis tool FlowDroid occur.
    	They contrast their style of analysis, which they refer to as qualitative, with prior analyses which take a more quantitative approach.
    	To support their analysis they created COVA, an extension to the Soot analysis framework which computes partial path constraints.
    	COVA can classify leaks, \ie taint flows, based on ``leak-constraints'' formed from conditions which depend on values from an invocation of a predefined ``constraint-API''.
    	A leak-constraint is the logical and of the conditions required for the source of the leak to be executed with the conditions required for the sink of the leak to be executed.
    	COVA was used to analyze the leaks reported by FloidDroid on 1,022 real-world Android applications.
    	By manually inspecting random sampled leaks the authors were able to remove 31% of the leaks due to incorrect sources, incorrect sinks, or source-sink pairs on the same object.
    	Using leak-constraints, the remaining leaks were classified as being constrained by input/output, user interface or configurations conditions; unconstrained; or infeasible.
    	The authors found that at least 20.53% of the leaks were constrained by one of the three conditions types.
        Luo \etal provide an alternative, non-quantitative approach to analyzing taint analysis tools.
    }
}

@inproceedings{Halfond:2006:UPT:1181775.1181797,
    author = {Halfond, William G. J. and Orso, Alessandro and Manolios, Panagiotis},
    title = {Using Positive Tainting and Syntax-aware Evaluation to Counter SQL Injection Attacks},
    booktitle = {Proceedings of the 14th ACM SIGSOFT International Symposium on Foundations of Software Engineering},
    series = {SIGSOFT '06/FSE-14},
    year = {2006},
    isbn = {1-59593-468-5},
    location = {Portland, Oregon, USA},
    pages = {175--185},
    numpages = {11},
    url = {http://doi.acm.org/10.1145/1181775.1181797},
    doi = {10.1145/1181775.1181797},
    acmid = {1181797},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {SQL injection, dynamic tainting, runtime monitoring},
    annote = {
    	Halfond \etal provide an automated technique for detecting and preventing SQL injection attacks.
    	Their technique uses ``positive-tainting'' which tracks the flow of trusted values (opposed to the more common approach of ``negative'' tainting which tracks untrusted values).
    	They prevent SQL injection attack by ensuring that certain syntactic parts of SQL queries are made from trusted values.
    	The authors' Java implementation of their technique, WASP, was evaluated on 7 web applications using 12,616 SQL injection attacks and 5,602 legitimate accesses.
    	WASP was able to correctly prevent all of the SQL attacks on the applications without preventing any legitimate accesses.
    	Unlike negative-tainting, Halfond \etal's positive-tainting has a diminished need for implicit flow considerations.
    	If taints are not propagated in an positive-tainting approach, for example due to implicit flows, then a false positive occurs.
    	False positives are easier to identify and correct than false negatives.
    	Thus, the impact not propagating taints due to an implicit flow is reduced. 
    }
}

@inproceedings{Clause:2009:PAI:1572272.1572301,
    author = {Clause, James and Orso, Alessandro},
    title = {Penumbra: Automatically Identifying Failure-relevant Inputs Using Dynamic Tainting},
    booktitle = {Proceedings of the Eighteenth International Symposium on Software Testing and Analysis},
    series = {ISSTA '09},
    year = {2009},
    isbn = {978-1-60558-338-9},
    location = {Chicago, IL, USA},
    pages = {249--260},
    numpages = {12},
    url = {http://doi.acm.org/10.1145/1572272.1572301},
    doi = {10.1145/1572272.1572301},
    acmid = {1572301},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {automated debugging, dynamic information flow, dynamic tainting, failure-relevant inputs},
    annote = {TODO}
}

@inproceedings{Huo:2014:IOQ:2635868.2635917,
    author = {Huo, Chen and Clause, James},
    title = {Improving Oracle Quality by Detecting Brittle Assertions and Unused Inputs in Tests},
    booktitle = {Proceedings of the 22Nd ACM SIGSOFT International Symposium on Foundations of Software Engineering},
    series = {FSE 2014},
    year = {2014},
    isbn = {978-1-4503-3056-5},
    location = {Hong Kong, China},
    pages = {621--631},
    numpages = {11},
    url = {http://doi.acm.org/10.1145/2635868.2635917},
    doi = {10.1145/2635868.2635917},
    acmid = {2635917},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {Brittleness, Dynamic tainting, Improving oracles, Mutation, Unit testing, Unused inputs},
    annote = {TODO}
}

@inproceedings{Hoschele:2016:MIG:2970276.2970321,
    author = {H\"{o}schele, Matthias and Zeller, Andreas},
    title = {Mining Input Grammars from Dynamic Taints},
    booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
    series = {ASE 2016},
    year = {2016},
    isbn = {978-1-4503-3845-5},
    location = {Singapore, Singapore},
    pages = {720--725},
    numpages = {6},
    url = {http://doi.acm.org/10.1145/2970276.2970321},
    doi = {10.1145/2970276.2970321},
    acmid = {2970321},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {Input formats, context-free grammars, dynamic tainting, fuzzing},
    annote = {TODO}
}
